{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/positmin/20220113/blob/main/00_1_word_embedding_basic_20221024.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NZccuM9fl2Xq"
      },
      "outputs": [],
      "source": [
        "## 20221024 10:10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "qKfY377LksJM"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.datasets import cifar10 # cifar 100까지 있음\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.optimizers import SGD, Adam, RMSprop\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "_D9PMsj8lLZ8"
      },
      "outputs": [],
      "source": [
        "## 10:42\n",
        "IMG_CHANNELS = 3 # 컬러사이즈 : parameter cnn은 채널 별로 filter를 적용 ## 채널 수만큼 파라미터가 늘어남\n",
        "IMG_ROWS = 32 # 이미지 사이즈는 32x32\n",
        "IMG_COLS = 32\n",
        "BATCH_SIZE = 128\n",
        "NB_EPOCH = 20\n",
        "NB_CLASSES = 10\n",
        "VERBOSE = 1\n",
        "VALIDATION_SPLIT = 0.2\n",
        "OPTIM = RMSprop()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xvqXutdfleB-",
        "outputId": "1db8d11c-1bde-4df9-aa60-afe373039e33"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170498071/170498071 [==============================] - 14s 0us/step\n",
            "X_train shape: (50000, 32, 32, 3)\n",
            "50000 train samples\n",
            "10000 test samples\n"
          ]
        }
      ],
      "source": [
        "(X_train, Y_train), (X_test, Y_test) = cifar10.load_data()\n",
        "print('X_train shape:', X_train.shape)\n",
        "print(X_train.shape[0], 'train samples')\n",
        "print(X_test.shape[0], 'test samples')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "opCZ0Ifnl0Pe"
      },
      "outputs": [],
      "source": [
        "# 범주가 2개인 경우\n",
        "# binary : target이 1개 예측\n",
        "# categorical : 2개로 예측\n",
        "# 신경망에서는 반드시 target은 one-hot-encoding 해줘야 한다\n",
        "Y_train = to_categorical(Y_train, NB_CLASSES)\n",
        "Y_test = to_categorical(Y_test, NB_CLASSES)\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_train /= 255\n",
        "X_test /= 255"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 515
        },
        "id": "QawrrqSSm-b7",
        "outputId": "c11338ff-10ba-4a63-b932-7ae28dd39d49"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.imshow(X_train[5])\n",
        "plt.grid(False)\n",
        "plt.show()\n",
        "plt.imshow(X_train[6])\n",
        "plt.grid(False)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fSnGdfy1nE4Z",
        "outputId": "8dd9efef-b303-4858-f620-603aea9ce9a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 32, 32, 32)        896       \n",
            "                                                                 \n",
            " activation (Activation)     (None, 32, 32, 32)        0         \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 16, 16, 32)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 16, 16, 32)        0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 8192)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 512)               4194816   \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 512)               0         \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                5130      \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 10)                0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,200,842\n",
            "Trainable params: 4,200,842\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model = Sequential()\n",
        "# 3이나 (3, 3)이나 동일\n",
        "# same : 입력이나 출력이나 이미지 사이즈가 동일\n",
        "model.add(Conv2D(32, (3, 3), padding='same', input_shape = (IMG_ROWS, IMG_COLS, IMG_CHANNELS))) \n",
        "# 배치사이즈 128 x IMG_ROWS  32 x 32 x 채널수 32\n",
        "model.add(Activation('relu'))\n",
        "# 사이즈가 행이나 열로 반으로 줄어듬\n",
        "model.add(MaxPooling2D(pool_size=(2,2))) # 배치사이즈 128 x 16 x 16 x 32\n",
        "model.add(Dropout(0.25)) # 사이즈에 영향을 미치지 않고, 회로의 계산 중에 25%를 생략해서 과적합을 방지 ## 10:50\n",
        "\n",
        "model.add(Flatten()) # 128 x() 16 x 16 x 32 ) # 이미지 한 장의 특성\n",
        "model.add(Dense(512)) # (16 x 16 x 32) x 512 => 128 x 512\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(NB_CLASSES)) # 512 x 10 => 128 x 10\n",
        "model.add(Activation('softmax')) # 확률값으로 전환\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RC5THDt2n3aq",
        "outputId": "02544b12-1a7a-4dc1-e262-48ddb11abd86"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "313/313 [==============================] - 12s 9ms/step - loss: 1.7233 - accuracy: 0.3924 - val_loss: 1.5348 - val_accuracy: 0.4507\n",
            "Epoch 2/20\n",
            "313/313 [==============================] - 2s 8ms/step - loss: 1.3775 - accuracy: 0.5091 - val_loss: 1.3087 - val_accuracy: 0.5418\n",
            "Epoch 3/20\n",
            "313/313 [==============================] - 2s 8ms/step - loss: 1.2475 - accuracy: 0.5594 - val_loss: 1.3192 - val_accuracy: 0.5477\n",
            "Epoch 4/20\n",
            "313/313 [==============================] - 2s 8ms/step - loss: 1.1630 - accuracy: 0.5903 - val_loss: 1.1936 - val_accuracy: 0.5769\n",
            "Epoch 5/20\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 1.0922 - accuracy: 0.6147 - val_loss: 1.0989 - val_accuracy: 0.6244\n",
            "Epoch 6/20\n",
            "313/313 [==============================] - 2s 8ms/step - loss: 1.0411 - accuracy: 0.6351 - val_loss: 1.1536 - val_accuracy: 0.6005\n",
            "Epoch 7/20\n",
            "313/313 [==============================] - 2s 8ms/step - loss: 0.9870 - accuracy: 0.6549 - val_loss: 1.0803 - val_accuracy: 0.6231\n",
            "Epoch 8/20\n",
            "313/313 [==============================] - 2s 8ms/step - loss: 0.9481 - accuracy: 0.6701 - val_loss: 1.0156 - val_accuracy: 0.6483\n",
            "Epoch 9/20\n",
            "313/313 [==============================] - 2s 8ms/step - loss: 0.9056 - accuracy: 0.6839 - val_loss: 1.1067 - val_accuracy: 0.6224\n",
            "Epoch 10/20\n",
            "313/313 [==============================] - 2s 8ms/step - loss: 0.8681 - accuracy: 0.6984 - val_loss: 1.0412 - val_accuracy: 0.6447\n",
            "Epoch 11/20\n",
            "313/313 [==============================] - 2s 8ms/step - loss: 0.8381 - accuracy: 0.7081 - val_loss: 1.1114 - val_accuracy: 0.6313\n",
            "Epoch 12/20\n",
            "313/313 [==============================] - 2s 8ms/step - loss: 0.8060 - accuracy: 0.7191 - val_loss: 1.0901 - val_accuracy: 0.6427\n",
            "Epoch 13/20\n",
            "313/313 [==============================] - 2s 8ms/step - loss: 0.7718 - accuracy: 0.7287 - val_loss: 1.0367 - val_accuracy: 0.6523\n",
            "Epoch 14/20\n",
            "313/313 [==============================] - 2s 8ms/step - loss: 0.7479 - accuracy: 0.7402 - val_loss: 1.0808 - val_accuracy: 0.6444\n",
            "Epoch 15/20\n",
            "313/313 [==============================] - 2s 8ms/step - loss: 0.7241 - accuracy: 0.7494 - val_loss: 1.0445 - val_accuracy: 0.6646\n",
            "Epoch 16/20\n",
            "313/313 [==============================] - 2s 8ms/step - loss: 0.6982 - accuracy: 0.7595 - val_loss: 1.0497 - val_accuracy: 0.6648\n",
            "Epoch 17/20\n",
            "313/313 [==============================] - 2s 8ms/step - loss: 0.6728 - accuracy: 0.7679 - val_loss: 0.9985 - val_accuracy: 0.6775\n",
            "Epoch 18/20\n",
            "313/313 [==============================] - 2s 8ms/step - loss: 0.6616 - accuracy: 0.7718 - val_loss: 1.0357 - val_accuracy: 0.6730\n",
            "Epoch 19/20\n",
            "313/313 [==============================] - 2s 8ms/step - loss: 0.6392 - accuracy: 0.7794 - val_loss: 1.0858 - val_accuracy: 0.6762\n",
            "Epoch 20/20\n",
            "313/313 [==============================] - 2s 8ms/step - loss: 0.6197 - accuracy: 0.7879 - val_loss: 1.1606 - val_accuracy: 0.6659\n"
          ]
        }
      ],
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer=OPTIM, metrics=['accuracy'])\n",
        "history = model.fit(X_train, Y_train, batch_size=BATCH_SIZE,\n",
        "                    epochs=NB_EPOCH, validation_split=VALIDATION_SPLIT, verbose=VERBOSE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PIB9V87IoIo6",
        "outputId": "7ca599bd-e0eb-49fc-f1ec-e4fd4d433683"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "79/79 [==============================] - 0s 4ms/step - loss: 1.1641 - accuracy: 0.6621\n",
            "\n",
            "Test loss: 1.1641292572021484\n",
            "Test accuracy: 0.6621000170707703\n"
          ]
        }
      ],
      "source": [
        "score = model.evaluate(X_test, Y_test, batch_size=BATCH_SIZE, verbose=VERBOSE)\n",
        "print(\"\\nTest loss:\", score[0]) ## 10:53\n",
        "print(\"Test accuracy:\", score[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uH7b2PmgslVM"
      },
      "source": [
        "# OCR : 카카오 id password\n",
        "# openAPI : \n",
        "  ### 키를 발급\n",
        "  ### 데이터를 카카오 전송한 다음 결과를 리턴 받음\n",
        "  ### 키는 REST API키로 전송\n",
        "  ### 실행 순서\n",
        "    - 이미지 리사이징\n",
        "    - 이미지 detect\n",
        "    - 이미지 recognization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "gHplvkPHo5h3"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import cv2\n",
        "import requests\n",
        "import sys\n",
        "LIMIT_PX = 1024\n",
        "LIMIT_BYTE = 1024*1024 # 1MB\n",
        "LIMIT_BOX = 40"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## 11:10"
      ],
      "metadata": {
        "id": "LBWi-NapzWhA"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# google OCR\n",
        "  ### optical character recognition\n",
        "  -30만원 정도\n",
        "  - 사용자 키 생성\n",
        "  - vision api를 위한 사용\n",
        "  -client sdk를 이용해서 인증 후 사용\n",
        "  # 지원하는 파일 형식\n",
        "- jpeg, png8, gif\n",
        "- 이미지 사이즈가 20m를 초과하면 안 됨 (길이 * 넓이)\n",
        "- vision api 특징\n",
        " - FACE_DETECTION 1600 x 1200 눈 사이 거리가 가장 중요합니다\n",
        " - LANDMARK_DETECTION 640 x 480\n",
        " - LOGO_DETECTION 640 x 480\n",
        " - LABEL_DETECTION 640 x 480\n",
        " - TEXT_DETECTION 및 DOCUMENT_TEXT_DETECTION 1024, 768의 경우 문자 감지를 위해 해상도가 더 높아야 합니다. SAFE_SEARCH_DETECTION  640x480"
      ],
      "metadata": {
        "id": "MYrWk_HK7FzR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def kakao_ocr_resize(image_path: str):\n",
        "  image = cv2.imread('/content/drive/MyDrive/00_05_1_daejeon/data/2마트영수증.jpg')\n",
        "  height, width, _ = image.shape\n",
        "  if LIMIT_PX < height or LIMIT_PX < width:\n",
        "    ratio = float(LIMIT_PX) / max(height,width)\n",
        "    # openAPI 요구하는 사이즈로 변경\n",
        "    image = cv2.resize(image, None, fx=ratio, fy=ratio)\n",
        "    height, width, _ = height, width, _ = image.shape\n",
        "    image_path= \"{}_resized.jpg\".format('2')\n",
        "    cv2.imwrite(image_path, image)\n",
        "    return image_path\n",
        "  return None"
      ],
      "metadata": {
        "id": "oYidUnr5uW8e"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# detection model은 모델을 확인하는 박스\n",
        "#def kakao_ocr_detect(image_path: str, appkey: str):\n",
        "#  API_URL = 'https://kapi.kakao.com/v1/vision/text/detect'\n",
        "#  headers = {'Authorization' : 'KakaoAK {}'.format('c81bab6a9c9e6c8084452872acb239d5')}\n",
        "#  image = cv2.imread('/content/drive/MyDrive/00_05_1_daejeon/data/2마트영수증.jpg')\n",
        "#  jpeg_image = cv2.imencode(\".jpg\", image)[1]\n",
        "#  data = jpeg_image.tobytes() # serialization해서 전송\n",
        "  # 네트워크는 두개의 송수신선 (광통신(빛으로 전송 : 발광/수광 -> 한 선으로 전송))\n",
        "  # post 방식으로 데이터 전송\n",
        "#  return requests.post(API_URL, headers = headers, files={\"file\": data}, data={\"boxes\": json.dumps(boxes)})"
      ],
      "metadata": {
        "id": "yyvudelmu768"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# detection model은 이미지인지 문자인지를 구별하는 박스\n",
        "#def kakao_ocr_recognize(image_path: str, boxes: list, appkey: str):\n",
        "#  API_URL = 'https://kapi.kakao.com/v1/vision/text/recognize'\n",
        "#  headers = {'Authorization': 'KakaoAK {}'.format('c81bab6a9c9e6c8084452872acb239d5')}\n",
        "#  image = cv2.imread('/content/drive/MyDrive/00_05_1_daejeon/data/2마트영수증.jpg')\n",
        "#  jpeg_image = cv2.imencode(\".jpg\", image)[1]\n",
        "#  data = jpeg_image.tobytes() # serialization해서 전송\n",
        "  # box 데이터 : detection 박스 : 문자 테두리 -> 문자를 인식(object detection - 해당 이미지에 박스를 쳐서 -> 박스 안에 있는 이미지를 인식)\n",
        "#  return requests.post(API_URL, headers = headers, files={\"file\": data}, data={\"boxes\": json.dumps(boxes)})"
      ],
      "metadata": {
        "id": "HbsGW77xvZVL"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def kakao_ocr(image_path: str, appkey: str):\n",
        "  \"\"\"\n",
        "  OCR api request example\n",
        "  :param image_path: 이미지파일 경로\n",
        "  :param appkey: 카카오 앱 REST API 키\n",
        "  \"\"\"\n",
        "  API_URL = 'https://dapi.kakao.com/v2/vision/text/ocr'\n",
        "  headers = {'Authorization': 'KakaoAK {}'.format(appkey)}\n",
        "  image = cv2.imread(image_path)\n",
        "  jpeg_image = cv2.imencode(\".jpg\", image)[1]\n",
        "  data = jpeg_image.tobytes()\n",
        "  return requests.post(API_URL, headers=headers, files={\"image\": data})"
      ],
      "metadata": {
        "id": "8W46pB1U-RwL"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "  # if len(sys.argv) != 3:\n",
        "  #   print(\"다시 실행하시오\")\n",
        "  image_path, appkey = '/content/drive/MyDrive/00_05_1_daejeon/data/2마트영수증.jpg', 'c81bab6a9c9e6c8084452872acb239d5'\n",
        "  resize_impath = kakao_ocr_resize(image_path)\n",
        "  if resize_impath is not None:\n",
        "    image_path = resize_impath\n",
        "    print(\"원본 대신 리사이즈된 이미지를 사용합니다.\")\n",
        "#  print(image_path)\n",
        "#  output = kakao_ocr_detect(image_path, appkey).json()\n",
        "#  print(\"[detect] output:\\n{}\\n\".format(output))\n",
        "#  boxes = output[\"result\"][\"boxes\"]\n",
        "#  boxes = boxes[:min(len(boxes), LIMIT_BOX)]\n",
        "#  output = kakao_ocr_recognize(image_path, boxes, appkey).json()\n",
        "  output = kakao_ocr(image_path, appkey).json() # REST API는 json 형태로 데이터를 송수신\n",
        "#  print(\"[recognize] output:\\n{}\\n\".format(json.dumps(output, sort_keys=True, indent=2)))\n",
        "  return output"
      ],
      "metadata": {
        "id": "-aY5GEC7wHhA"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "main() ## 12:10"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "949KUC8Qw8j4",
        "outputId": "a29748b1-2d85-44c4-9672-732dc17c5291"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'result': [{'boxes': [[47, 18], [72, 18], [72, 45], [47, 45]],\n",
              "   'recognition_words': ['흐']},\n",
              "  {'boxes': [[141, 17], [188, 17], [188, 46], [141, 46]],\n",
              "   'recognition_words': ['농협']},\n",
              "  {'boxes': [[39, 52], [66, 51], [66, 63], [40, 65]],\n",
              "   'recognition_words': ['경기']},\n",
              "  {'boxes': [[72, 49], [124, 49], [124, 66], [72, 66]],\n",
              "   'recognition_words': ['의정부시']},\n",
              "  {'boxes': [[156, 64], [181, 64], [181, 78], [156, 78]],\n",
              "   'recognition_words': ['전화']},\n",
              "  {'boxes': [[186, 64], [207, 64], [207, 78], [186, 78]],\n",
              "   'recognition_words': ['031']},\n",
              "  {'boxes': [[124, 76], [158, 76], [158, 88], [124, 88]],\n",
              "   'recognition_words': ['*****']},\n",
              "  {'boxes': [[161, 87], [214, 86], [214, 99], [162, 101]],\n",
              "   'recognition_words': ['nonghyue']},\n",
              "  {'boxes': [[217, 90], [245, 89], [245, 99], [218, 101]],\n",
              "   'recognition_words': ['com/']},\n",
              "  {'boxes': [[9, 94], [49, 98], [48, 112], [7, 109]],\n",
              "   'recognition_words': ['영수증']},\n",
              "  {'boxes': [[53, 98], [105, 98], [105, 114], [53, 114]],\n",
              "   'recognition_words': ['미지참시']},\n",
              "  {'boxes': [[110, 100], [135, 100], [135, 113], [110, 113]],\n",
              "   'recognition_words': ['교환']},\n",
              "  {'boxes': [[141, 99], [154, 99], [154, 112], [141, 112]],\n",
              "   'recognition_words': ['한']},\n",
              "  {'boxes': [[155, 99], [167, 99], [167, 112], [155, 112]],\n",
              "   'recognition_words': ['불']},\n",
              "  {'boxes': [[172, 99], [253, 96], [254, 113], [172, 115]],\n",
              "   'recognition_words': ['불가(30일내)']},\n",
              "  {'boxes': [[7, 110], [51, 108], [51, 124], [8, 125]],\n",
              "   'recognition_words': ['교환/환']},\n",
              "  {'boxes': [[72, 111], [109, 111], [109, 124], [72, 124]],\n",
              "   'recognition_words': ['구매점']},\n",
              "  {'boxes': [[110, 111], [135, 112], [135, 124], [109, 122]],\n",
              "   'recognition_words': ['에서']},\n",
              "  {'boxes': [[141, 112], [167, 113], [167, 125], [140, 123]],\n",
              "   'recognition_words': ['가능']},\n",
              "  {'boxes': [[8, 134], [47, 132], [47, 151], [9, 152]],\n",
              "   'recognition_words': ['김감소']},\n",
              "  {'boxes': [[77, 133], [146, 132], [146, 147], [78, 149]],\n",
              "   'recognition_words': ['2015-11-03']},\n",
              "  {'boxes': [[149, 133], [203, 135], [203, 150], [148, 147]],\n",
              "   'recognition_words': ['16:31:53']},\n",
              "  {'boxes': [[212, 134], [276, 134], [276, 149], [212, 149]],\n",
              "   'recognition_words': ['0002-00085']},\n",
              "  {'boxes': [[9, 144], [74, 144], [74, 163], [9, 163]],\n",
              "   'recognition_words': ['상품(코드)']},\n",
              "  {'boxes': [[136, 145], [162, 145], [162, 164], [136, 164]],\n",
              "   'recognition_words': ['단가']},\n",
              "  {'boxes': [[188, 145], [212, 145], [212, 160], [188, 160]],\n",
              "   'recognition_words': ['수량']},\n",
              "  {'boxes': [[250, 147], [276, 147], [276, 160], [250, 160]],\n",
              "   'recognition_words': ['금액']},\n",
              "  {'boxes': [[8, 170], [29, 168], [29, 181], [8, 182]],\n",
              "   'recognition_words': ['001']},\n",
              "  {'boxes': [[36, 167], [110, 168], [110, 184], [35, 182]],\n",
              "   'recognition_words': ['P굿모닝우유']},\n",
              "  {'boxes': [[116, 169], [149, 168], [149, 182], [117, 184]],\n",
              "   'recognition_words': ['900ML']},\n",
              "  {'boxes': [[232, 169], [246, 169], [246, 184], [232, 184]],\n",
              "   'recognition_words': ['[2']},\n",
              "  {'boxes': [[251, 170], [276, 170], [276, 182], [251, 182]],\n",
              "   'recognition_words': ['150]']},\n",
              "  {'boxes': [[136, 179], [170, 179], [170, 195], [136, 195]],\n",
              "   'recognition_words': ['1,350']},\n",
              "  {'boxes': [[243, 184], [277, 182], [277, 193], [244, 196]],\n",
              "   'recognition_words': ['1,350']},\n",
              "  {'boxes': [[9, 193], [29, 193], [29, 207], [9, 207]],\n",
              "   'recognition_words': ['002']},\n",
              "  {'boxes': [[35, 193], [74, 193], [74, 206], [35, 206]],\n",
              "   'recognition_words': ['P양파']},\n",
              "  {'boxes': [[9, 203], [56, 202], [57, 217], [10, 218]],\n",
              "   'recognition_words': ['*231973']},\n",
              "  {'boxes': [[136, 203], [170, 203], [170, 219], [136, 219]],\n",
              "   'recognition_words': ['3,300']},\n",
              "  {'boxes': [[243, 204], [277, 204], [277, 220], [243, 220]],\n",
              "   'recognition_words': ['3,300']},\n",
              "  {'boxes': [[8, 216], [29, 215], [30, 228], [9, 229]],\n",
              "   'recognition_words': ['003']},\n",
              "  {'boxes': [[35, 216], [59, 216], [59, 229], [35, 229]],\n",
              "   'recognition_words': ['P무']},\n",
              "  {'boxes': [[9, 228], [55, 226], [56, 240], [10, 242]],\n",
              "   'recognition_words': ['*231913']},\n",
              "  {'boxes': [[149, 228], [169, 228], [169, 241], [149, 241]],\n",
              "   'recognition_words': ['500']},\n",
              "  {'boxes': [[257, 228], [277, 228], [277, 242], [257, 242]],\n",
              "   'recognition_words': ['500']},\n",
              "  {'boxes': [[8, 240], [29, 239], [29, 252], [9, 253]],\n",
              "   'recognition_words': ['004']},\n",
              "  {'boxes': [[35, 237], [73, 238], [73, 253], [34, 252]],\n",
              "   'recognition_words': ['P깻잎']},\n",
              "  {'boxes': [[79, 246], [88, 246], [88, 257], [79, 257]],\n",
              "   'recognition_words': ['.']},\n",
              "  {'boxes': [[9, 252], [54, 250], [54, 262], [10, 265]],\n",
              "   'recognition_words': ['*231308']},\n",
              "  {'boxes': [[149, 252], [169, 251], [169, 263], [150, 265]],\n",
              "   'recognition_words': ['750']},\n",
              "  {'boxes': [[257, 251], [277, 251], [277, 265], [257, 265]],\n",
              "   'recognition_words': ['750']},\n",
              "  {'boxes': [[8, 262], [29, 261], [30, 276], [9, 277]],\n",
              "   'recognition_words': ['005']},\n",
              "  {'boxes': [[34, 262], [85, 262], [85, 276], [34, 276]],\n",
              "   'recognition_words': ['P하선정']},\n",
              "  {'boxes': [[90, 262], [141, 261], [141, 277], [91, 279]],\n",
              "   'recognition_words': ['바로먹기']},\n",
              "  {'boxes': [[156, 261], [203, 261], [203, 278], [156, 278]],\n",
              "   'recognition_words': ['은장아찌']},\n",
              "  {'boxes': [[213, 262], [239, 263], [239, 279], [212, 277]],\n",
              "   'recognition_words': ['150g']},\n",
              "  {'boxes': [[14, 273], [99, 275], [99, 289], [13, 286]],\n",
              "   'recognition_words': ['8801007265889']},\n",
              "  {'boxes': [[244, 274], [277, 273], [277, 287], [245, 289]],\n",
              "   'recognition_words': ['1,380']},\n",
              "  {'boxes': [[139, 278], [170, 277], [170, 288], [140, 290]],\n",
              "   'recognition_words': ['1,380']},\n",
              "  {'boxes': [[9, 287], [29, 287], [29, 299], [9, 299]],\n",
              "   'recognition_words': ['006']},\n",
              "  {'boxes': [[36, 286], [98, 286], [98, 300], [36, 300]],\n",
              "   'recognition_words': ['P브로커리']},\n",
              "  {'boxes': [[9, 298], [55, 298], [55, 313], [9, 313]],\n",
              "   'recognition_words': ['*232285']},\n",
              "  {'boxes': [[136, 297], [170, 297], [170, 315], [136, 315]],\n",
              "   'recognition_words': ['1.280']},\n",
              "  {'boxes': [[243, 297], [277, 296], [277, 317], [244, 319]],\n",
              "   'recognition_words': ['1.280']},\n",
              "  {'boxes': [[124, 322], [135, 322], [135, 335], [124, 335]],\n",
              "   'recognition_words': ['매']},\n",
              "  {'boxes': [[237, 322], [244, 322], [244, 335], [237, 335]],\n",
              "   'recognition_words': ['8']},\n",
              "  {'boxes': [[249, 320], [276, 320], [276, 340], [249, 340]],\n",
              "   'recognition_words': ['560']},\n",
              "  {'boxes': [[103, 344], [143, 349], [139, 380], [98, 374]],\n",
              "   'recognition_words': ['박을']},\n",
              "  {'boxes': [[142, 343], [155, 343], [155, 360], [142, 360]],\n",
              "   'recognition_words': ['금']},\n",
              "  {'boxes': [[237, 346], [244, 346], [244, 359], [237, 359]],\n",
              "   'recognition_words': ['8']},\n",
              "  {'boxes': [[248, 346], [270, 345], [270, 358], [249, 360]],\n",
              "   'recognition_words': ['560']},\n",
              "  {'boxes': [[238, 357], [244, 357], [244, 369], [238, 369]],\n",
              "   'recognition_words': ['8']},\n",
              "  {'boxes': [[250, 357], [270, 357], [270, 370], [250, 370]],\n",
              "   'recognition_words': ['560']},\n",
              "  {'boxes': [[41, 367], [53, 367], [53, 383], [41, 383]],\n",
              "   'recognition_words': ['>>']},\n",
              "  {'boxes': [[61, 376], [175, 379], [174, 412], [60, 408]],\n",
              "   'recognition_words': ['']},\n",
              "  {'boxes': [[249, 381], [270, 380], [270, 392], [250, 394]],\n",
              "   'recognition_words': ['180']},\n",
              "  {'boxes': [[249, 393], [271, 392], [271, 404], [250, 406]],\n",
              "   'recognition_words': ['255']},\n",
              "  {'boxes': [[250, 402], [270, 401], [270, 414], [250, 415]],\n",
              "   'recognition_words': ['125']},\n",
              "  {'boxes': [[9, 426], [60, 426], [60, 443], [9, 443]],\n",
              "   'recognition_words': ['바코드앞']},\n",
              "  {'boxes': [[79, 425], [104, 425], [104, 445], [79, 445]],\n",
              "   'recognition_words': ['면세']},\n",
              "  {'boxes': [[129, 425], [157, 425], [157, 447], [129, 447]],\n",
              "   'recognition_words': ['영세']},\n",
              "  {'boxes': [[167, 427], [205, 426], [206, 442], [167, 444]],\n",
              "   'recognition_words': ['상품명']},\n",
              "  {'boxes': [[214, 427], [249, 427], [249, 441], [214, 441]],\n",
              "   'recognition_words': ['P포인']},\n",
              "  {'boxes': [[9, 449], [33, 451], [33, 464], [8, 463]],\n",
              "   'recognition_words': ['회원']},\n",
              "  {'boxes': [[129, 450], [161, 451], [160, 463], [129, 461]],\n",
              "   'recognition_words': ['박*분']},\n",
              "  {'boxes': [[168, 450], [181, 450], [180, 465], [166, 464]],\n",
              "   'recognition_words': ['님']},\n",
              "  {'boxes': [[98, 462], [172, 462], [172, 477], [98, 477]],\n",
              "   'recognition_words': ['우수고객포인']},\n",
              "  {'boxes': [[263, 462], [277, 462], [277, 475], [263, 475]],\n",
              "   'recognition_words': ['40']},\n",
              "  {'boxes': [[118, 475], [128, 475], [128, 487], [118, 487]],\n",
              "   'recognition_words': ['여']},\n",
              "  {'boxes': [[137, 475], [146, 475], [146, 488], [137, 488]],\n",
              "   'recognition_words': ['포']},\n",
              "  {'boxes': [[155, 472], [168, 472], [168, 486], [155, 486]],\n",
              "   'recognition_words': ['인']},\n",
              "  {'boxes': [[263, 473], [277, 473], [277, 489], [263, 489]],\n",
              "   'recognition_words': ['98']},\n",
              "  {'boxes': [[238, 479], [276, 480], [275, 502], [237, 501]],\n",
              "   'recognition_words': ['14:190']},\n",
              "  {'boxes': [[135, 484], [173, 485], [173, 500], [134, 498]],\n",
              "   'recognition_words': ['능포인']},\n",
              "  {'boxes': [[23, 509], [61, 510], [61, 521], [23, 519]],\n",
              "   'recognition_words': ['******']},\n",
              "  {'boxes': [[67, 509], [79, 509], [79, 522], [67, 522]],\n",
              "   'recognition_words': ['신']},\n",
              "  {'boxes': [[79, 508], [116, 508], [116, 522], [79, 522]],\n",
              "   'recognition_words': ['용카드']},\n",
              "  {'boxes': [[123, 509], [135, 510], [135, 522], [122, 520]],\n",
              "   'recognition_words': ['O']},\n",
              "  {'boxes': [[133, 510], [152, 509], [152, 521], [134, 523]],\n",
              "   'recognition_words': ['출']},\n",
              "  {'boxes': [[206, 509], [226, 509], [226, 522], [206, 522]],\n",
              "   'recognition_words': ['용)']},\n",
              "  {'boxes': [[67, 533], [92, 533], [92, 546], [67, 546]],\n",
              "   'recognition_words': ['4902']},\n",
              "  {'boxes': [[140, 534], [170, 535], [170, 546], [139, 544]],\n",
              "   'recognition_words': ['*****']},\n",
              "  {'boxes': [[8, 542], [34, 543], [33, 559], [7, 557]],\n",
              "   'recognition_words': ['할부']},\n",
              "  {'boxes': [[36, 544], [66, 546], [66, 558], [35, 557]],\n",
              "   'recognition_words': [':00개']},\n",
              "  {'boxes': [[67, 545], [77, 545], [77, 559], [67, 559]],\n",
              "   'recognition_words': ['1E']},\n",
              "  {'boxes': [[135, 544], [173, 545], [173, 559], [134, 557]],\n",
              "   'recognition_words': ['매출금']},\n",
              "  {'boxes': [[175, 544], [194, 544], [194, 557], [175, 557]],\n",
              "   'recognition_words': ['액:']},\n",
              "  {'boxes': [[231, 544], [243, 544], [243, 558], [231, 558]],\n",
              "   'recognition_words': ['8.']},\n",
              "  {'boxes': [[244, 543], [274, 544], [274, 558], [243, 556]],\n",
              "   'recognition_words': ['560원']},\n",
              "  {'boxes': [[36, 557], [54, 559], [53, 570], [34, 567]],\n",
              "   'recognition_words': ['No:']},\n",
              "  {'boxes': [[54, 555], [102, 554], [103, 568], [55, 569]],\n",
              "   'recognition_words': ['75513401']},\n",
              "  {'boxes': [[135, 556], [174, 558], [172, 582], [134, 579]],\n",
              "   'recognition_words': ['가간트로']},\n",
              "  {'boxes': [[174, 555], [250, 553], [250, 567], [175, 570]],\n",
              "   'recognition_words': [':00000074900']},\n",
              "  {'boxes': [[63, 568], [118, 566], [118, 580], [64, 583]],\n",
              "   'recognition_words': ['20151103']},\n",
              "  {'boxes': [[173, 567], [239, 566], [240, 580], [174, 582]],\n",
              "   'recognition_words': ['사:KIS(V3)']},\n",
              "  {'boxes': [[22, 602], [34, 602], [34, 616], [22, 616]],\n",
              "   'recognition_words': ['은']},\n",
              "  {'boxes': [[40, 601], [66, 602], [66, 617], [39, 615]],\n",
              "   'recognition_words': ['하루']},\n",
              "  {'boxes': [[72, 602], [117, 602], [117, 618], [72, 618]],\n",
              "   'recognition_words': ['되세요!']},\n",
              "  {'boxes': [[9, 614], [20, 614], [20, 628], [9, 628]],\n",
              "   'recognition_words': ['언']},\n",
              "  {'boxes': [[111, 615], [136, 615], [136, 629], [111, 629]],\n",
              "   'recognition_words': ['위해']},\n",
              "  {'boxes': [[141, 613], [181, 611], [181, 628], [141, 630]],\n",
              "   'recognition_words': ['최선을']},\n",
              "  {'boxes': [[187, 612], [264, 613], [264, 635], [186, 633]],\n",
              "   'recognition_words': ['당하겠용님당']}]}"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 시계열 분석\n",
        "### 12:22"
      ],
      "metadata": {
        "id": "r7qtP4bMALip"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas\n",
        "import math\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "numpy.random.seed(7)\n",
        "dataframe = pandas.read_csv('/content/drive/MyDrive/00_05_1_daejeon/data/Passengers.csv', usecols=[1], engine='python', skipfooter=3) # uncols=[1]\n",
        "dataset = dataframe.values\n",
        "#dataset = dataset.astype('float32')\n",
        "train_size = int(len(dataset) * 0.67)\n",
        "test_size = len(dataset) - train_size\n",
        "train, test = dataset[0:train_size,:], dataset[train_size:len(dataset),:]\n",
        "print(len(train), len(test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fGEZFCRh1PTK",
        "outputId": "dffdf68f-767b-4287-cda2-a2d6d35099f4"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "94 47\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(dataframe.head())\n",
        "len(dataframe)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ztQgLg4BcYa",
        "outputId": "fbb8445c-48d8-431a-a0c9-fbd7bc54a076"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Passengers\n",
            "0         112\n",
            "1         118\n",
            "2         132\n",
            "3         129\n",
            "4         121\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "141"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test.shape\n",
        "test\n",
        "# 자기 상관성 띄고 있는 데이터\n",
        "# 독립변수와 종속변수가 순서대로 지정"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fvA6E-tTEKOZ",
        "outputId": "1297bafd-27d5-4bf6-d2bf-7d130515f391"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[271],\n",
              "       [306],\n",
              "       [315],\n",
              "       [301],\n",
              "       [356],\n",
              "       [348],\n",
              "       [355],\n",
              "       [422],\n",
              "       [465],\n",
              "       [467],\n",
              "       [404],\n",
              "       [347],\n",
              "       [305],\n",
              "       [336],\n",
              "       [340],\n",
              "       [318],\n",
              "       [362],\n",
              "       [348],\n",
              "       [363],\n",
              "       [435],\n",
              "       [491],\n",
              "       [505],\n",
              "       [404],\n",
              "       [359],\n",
              "       [310],\n",
              "       [337],\n",
              "       [360],\n",
              "       [342],\n",
              "       [406],\n",
              "       [396],\n",
              "       [420],\n",
              "       [472],\n",
              "       [548],\n",
              "       [559],\n",
              "       [463],\n",
              "       [407],\n",
              "       [362],\n",
              "       [405],\n",
              "       [417],\n",
              "       [391],\n",
              "       [419],\n",
              "       [461],\n",
              "       [472],\n",
              "       [535],\n",
              "       [622],\n",
              "       [606],\n",
              "       [508]])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_dataset(dataset, look_back=1):\n",
        "  dataX, dataY = [], [] # 독립변수, 종속변수\n",
        "  for i in range(len(dataset)-look_back-1): # 종료시점\n",
        "    # 범위로 하면 look_back 위치는 제외\n",
        "    a = dataset[i:(i+look_back), 0] # 4개 # 앞의 3개는 종속 변수 없음 ## 12:38\n",
        "    dataX.append(a)\n",
        "    dataY.append(dataset[i + look_back, 0])\n",
        "    ## 루프백이 있는 얘를 종속변수로 해주면 됨\n",
        "  return numpy.array(dataX), numpy.array(dataY)"
      ],
      "metadata": {
        "id": "FdwbLorTBnOp"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "look_back = 2 # 독립변수의 개수\n",
        "trainX, trainY = create_dataset(train, look_back)\n",
        "testX, testY = create_dataset(test, look_back)\n",
        "print(trainX[:3], trainY[:3])\n",
        "#print(trainY)\n",
        "train[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0hoe871sCCMJ",
        "outputId": "a1aae94f-58c7-46b8-b79a-021e804bb56b"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[112 118]\n",
            " [118 132]\n",
            " [132 129]] [132 129 121]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[112],\n",
              "       [118],\n",
              "       [132],\n",
              "       [129],\n",
              "       [121]])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## 12:46\n",
        "# Train Score: 479.21 MSE (21.89 RMSE)\n",
        "# Test Score: 1885.58 MSE (43.42 RMSE)\n",
        "# 학습된 데이터는 99%까지 => 데이터가 있는 경우 + TM(뉴시), 이자율변동, 유동성 분석\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(8, input_dim=look_back, activation='relu')) # 2x8\n",
        "model.add(Dense(1)) # 8x1 행렬\n",
        "# 예측 : MSE loss function\n",
        "model.compile(loss='mean_squared_error', optimizer='adam')\n",
        "model.fit(trainX, trainY, epochs = 200, batch_size=2, verbose=2)\n",
        "trainScore = model.evaluate(trainX, trainY, verbose=0)\n",
        "print('Train Score: %.2f MSE (%.2f RMSE)' % (trainScore, math.sqrt(trainScore)))\n",
        "testScore = model.evaluate(testX, testY, verbose=0)\n",
        "print('Test Score: %.2f MSE (%.2f RMSE)' % (testScore, math.sqrt(testScore)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FRm84elCCJFY",
        "outputId": "38afea5a-3935-4790-b506-fbbf28782079"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "46/46 - 0s - loss: 105011.4141 - 441ms/epoch - 10ms/step\n",
            "Epoch 2/200\n",
            "46/46 - 0s - loss: 80183.0078 - 98ms/epoch - 2ms/step\n",
            "Epoch 3/200\n",
            "46/46 - 0s - loss: 59316.8750 - 94ms/epoch - 2ms/step\n",
            "Epoch 4/200\n",
            "46/46 - 0s - loss: 42018.9492 - 109ms/epoch - 2ms/step\n",
            "Epoch 5/200\n",
            "46/46 - 0s - loss: 28034.4062 - 102ms/epoch - 2ms/step\n",
            "Epoch 6/200\n",
            "46/46 - 0s - loss: 16985.4844 - 95ms/epoch - 2ms/step\n",
            "Epoch 7/200\n",
            "46/46 - 0s - loss: 9522.7119 - 94ms/epoch - 2ms/step\n",
            "Epoch 8/200\n",
            "46/46 - 0s - loss: 4831.9858 - 96ms/epoch - 2ms/step\n",
            "Epoch 9/200\n",
            "46/46 - 0s - loss: 2295.7117 - 100ms/epoch - 2ms/step\n",
            "Epoch 10/200\n",
            "46/46 - 0s - loss: 1185.2111 - 94ms/epoch - 2ms/step\n",
            "Epoch 11/200\n",
            "46/46 - 0s - loss: 766.4844 - 92ms/epoch - 2ms/step\n",
            "Epoch 12/200\n",
            "46/46 - 0s - loss: 630.3615 - 97ms/epoch - 2ms/step\n",
            "Epoch 13/200\n",
            "46/46 - 0s - loss: 584.4628 - 94ms/epoch - 2ms/step\n",
            "Epoch 14/200\n",
            "46/46 - 0s - loss: 568.7056 - 103ms/epoch - 2ms/step\n",
            "Epoch 15/200\n",
            "46/46 - 0s - loss: 568.5125 - 95ms/epoch - 2ms/step\n",
            "Epoch 16/200\n",
            "46/46 - 0s - loss: 564.0745 - 90ms/epoch - 2ms/step\n",
            "Epoch 17/200\n",
            "46/46 - 0s - loss: 557.2946 - 98ms/epoch - 2ms/step\n",
            "Epoch 18/200\n",
            "46/46 - 0s - loss: 555.8923 - 99ms/epoch - 2ms/step\n",
            "Epoch 19/200\n",
            "46/46 - 0s - loss: 560.5154 - 99ms/epoch - 2ms/step\n",
            "Epoch 20/200\n",
            "46/46 - 0s - loss: 556.8194 - 93ms/epoch - 2ms/step\n",
            "Epoch 21/200\n",
            "46/46 - 0s - loss: 556.0342 - 92ms/epoch - 2ms/step\n",
            "Epoch 22/200\n",
            "46/46 - 0s - loss: 552.9091 - 285ms/epoch - 6ms/step\n",
            "Epoch 23/200\n",
            "46/46 - 0s - loss: 550.3619 - 91ms/epoch - 2ms/step\n",
            "Epoch 24/200\n",
            "46/46 - 0s - loss: 552.2045 - 94ms/epoch - 2ms/step\n",
            "Epoch 25/200\n",
            "46/46 - 0s - loss: 550.0953 - 95ms/epoch - 2ms/step\n",
            "Epoch 26/200\n",
            "46/46 - 0s - loss: 548.8525 - 91ms/epoch - 2ms/step\n",
            "Epoch 27/200\n",
            "46/46 - 0s - loss: 549.0908 - 95ms/epoch - 2ms/step\n",
            "Epoch 28/200\n",
            "46/46 - 0s - loss: 545.2560 - 106ms/epoch - 2ms/step\n",
            "Epoch 29/200\n",
            "46/46 - 0s - loss: 544.8563 - 109ms/epoch - 2ms/step\n",
            "Epoch 30/200\n",
            "46/46 - 0s - loss: 545.5087 - 91ms/epoch - 2ms/step\n",
            "Epoch 31/200\n",
            "46/46 - 0s - loss: 543.6293 - 98ms/epoch - 2ms/step\n",
            "Epoch 32/200\n",
            "46/46 - 0s - loss: 545.6961 - 120ms/epoch - 3ms/step\n",
            "Epoch 33/200\n",
            "46/46 - 0s - loss: 543.1398 - 102ms/epoch - 2ms/step\n",
            "Epoch 34/200\n",
            "46/46 - 0s - loss: 546.9194 - 98ms/epoch - 2ms/step\n",
            "Epoch 35/200\n",
            "46/46 - 0s - loss: 547.9669 - 92ms/epoch - 2ms/step\n",
            "Epoch 36/200\n",
            "46/46 - 0s - loss: 543.9219 - 92ms/epoch - 2ms/step\n",
            "Epoch 37/200\n",
            "46/46 - 0s - loss: 547.7957 - 97ms/epoch - 2ms/step\n",
            "Epoch 38/200\n",
            "46/46 - 0s - loss: 547.4733 - 91ms/epoch - 2ms/step\n",
            "Epoch 39/200\n",
            "46/46 - 0s - loss: 542.6210 - 91ms/epoch - 2ms/step\n",
            "Epoch 40/200\n",
            "46/46 - 0s - loss: 545.5336 - 90ms/epoch - 2ms/step\n",
            "Epoch 41/200\n",
            "46/46 - 0s - loss: 546.2304 - 95ms/epoch - 2ms/step\n",
            "Epoch 42/200\n",
            "46/46 - 0s - loss: 540.9803 - 107ms/epoch - 2ms/step\n",
            "Epoch 43/200\n",
            "46/46 - 0s - loss: 546.6497 - 90ms/epoch - 2ms/step\n",
            "Epoch 44/200\n",
            "46/46 - 0s - loss: 543.4313 - 88ms/epoch - 2ms/step\n",
            "Epoch 45/200\n",
            "46/46 - 0s - loss: 539.7460 - 93ms/epoch - 2ms/step\n",
            "Epoch 46/200\n",
            "46/46 - 0s - loss: 539.1476 - 102ms/epoch - 2ms/step\n",
            "Epoch 47/200\n",
            "46/46 - 0s - loss: 538.6903 - 103ms/epoch - 2ms/step\n",
            "Epoch 48/200\n",
            "46/46 - 0s - loss: 540.0669 - 91ms/epoch - 2ms/step\n",
            "Epoch 49/200\n",
            "46/46 - 0s - loss: 538.7515 - 89ms/epoch - 2ms/step\n",
            "Epoch 50/200\n",
            "46/46 - 0s - loss: 556.5274 - 94ms/epoch - 2ms/step\n",
            "Epoch 51/200\n",
            "46/46 - 0s - loss: 533.2576 - 96ms/epoch - 2ms/step\n",
            "Epoch 52/200\n",
            "46/46 - 0s - loss: 546.8175 - 91ms/epoch - 2ms/step\n",
            "Epoch 53/200\n",
            "46/46 - 0s - loss: 535.3866 - 96ms/epoch - 2ms/step\n",
            "Epoch 54/200\n",
            "46/46 - 0s - loss: 553.3412 - 90ms/epoch - 2ms/step\n",
            "Epoch 55/200\n",
            "46/46 - 0s - loss: 534.6923 - 96ms/epoch - 2ms/step\n",
            "Epoch 56/200\n",
            "46/46 - 0s - loss: 538.2523 - 97ms/epoch - 2ms/step\n",
            "Epoch 57/200\n",
            "46/46 - 0s - loss: 549.2510 - 91ms/epoch - 2ms/step\n",
            "Epoch 58/200\n",
            "46/46 - 0s - loss: 536.3004 - 94ms/epoch - 2ms/step\n",
            "Epoch 59/200\n",
            "46/46 - 0s - loss: 539.9868 - 91ms/epoch - 2ms/step\n",
            "Epoch 60/200\n",
            "46/46 - 0s - loss: 541.0283 - 96ms/epoch - 2ms/step\n",
            "Epoch 61/200\n",
            "46/46 - 0s - loss: 533.2593 - 95ms/epoch - 2ms/step\n",
            "Epoch 62/200\n",
            "46/46 - 0s - loss: 530.1983 - 94ms/epoch - 2ms/step\n",
            "Epoch 63/200\n",
            "46/46 - 0s - loss: 536.1659 - 101ms/epoch - 2ms/step\n",
            "Epoch 64/200\n",
            "46/46 - 0s - loss: 534.2803 - 95ms/epoch - 2ms/step\n",
            "Epoch 65/200\n",
            "46/46 - 0s - loss: 532.2631 - 95ms/epoch - 2ms/step\n",
            "Epoch 66/200\n",
            "46/46 - 0s - loss: 545.9499 - 93ms/epoch - 2ms/step\n",
            "Epoch 67/200\n",
            "46/46 - 0s - loss: 535.9120 - 93ms/epoch - 2ms/step\n",
            "Epoch 68/200\n",
            "46/46 - 0s - loss: 526.9875 - 113ms/epoch - 2ms/step\n",
            "Epoch 69/200\n",
            "46/46 - 0s - loss: 552.2737 - 91ms/epoch - 2ms/step\n",
            "Epoch 70/200\n",
            "46/46 - 0s - loss: 529.7751 - 91ms/epoch - 2ms/step\n",
            "Epoch 71/200\n",
            "46/46 - 0s - loss: 529.7903 - 95ms/epoch - 2ms/step\n",
            "Epoch 72/200\n",
            "46/46 - 0s - loss: 533.9525 - 92ms/epoch - 2ms/step\n",
            "Epoch 73/200\n",
            "46/46 - 0s - loss: 534.1425 - 104ms/epoch - 2ms/step\n",
            "Epoch 74/200\n",
            "46/46 - 0s - loss: 537.8480 - 92ms/epoch - 2ms/step\n",
            "Epoch 75/200\n",
            "46/46 - 0s - loss: 531.2401 - 91ms/epoch - 2ms/step\n",
            "Epoch 76/200\n",
            "46/46 - 0s - loss: 540.5334 - 91ms/epoch - 2ms/step\n",
            "Epoch 77/200\n",
            "46/46 - 0s - loss: 536.0597 - 94ms/epoch - 2ms/step\n",
            "Epoch 78/200\n",
            "46/46 - 0s - loss: 525.3311 - 92ms/epoch - 2ms/step\n",
            "Epoch 79/200\n",
            "46/46 - 0s - loss: 529.3382 - 90ms/epoch - 2ms/step\n",
            "Epoch 80/200\n",
            "46/46 - 0s - loss: 536.0274 - 91ms/epoch - 2ms/step\n",
            "Epoch 81/200\n",
            "46/46 - 0s - loss: 535.3360 - 91ms/epoch - 2ms/step\n",
            "Epoch 82/200\n",
            "46/46 - 0s - loss: 543.3834 - 105ms/epoch - 2ms/step\n",
            "Epoch 83/200\n",
            "46/46 - 0s - loss: 523.9153 - 104ms/epoch - 2ms/step\n",
            "Epoch 84/200\n",
            "46/46 - 0s - loss: 527.6074 - 93ms/epoch - 2ms/step\n",
            "Epoch 85/200\n",
            "46/46 - 0s - loss: 540.8998 - 92ms/epoch - 2ms/step\n",
            "Epoch 86/200\n",
            "46/46 - 0s - loss: 528.4919 - 94ms/epoch - 2ms/step\n",
            "Epoch 87/200\n",
            "46/46 - 0s - loss: 516.3188 - 92ms/epoch - 2ms/step\n",
            "Epoch 88/200\n",
            "46/46 - 0s - loss: 522.1646 - 96ms/epoch - 2ms/step\n",
            "Epoch 89/200\n",
            "46/46 - 0s - loss: 521.0878 - 91ms/epoch - 2ms/step\n",
            "Epoch 90/200\n",
            "46/46 - 0s - loss: 524.3508 - 98ms/epoch - 2ms/step\n",
            "Epoch 91/200\n",
            "46/46 - 0s - loss: 524.4205 - 96ms/epoch - 2ms/step\n",
            "Epoch 92/200\n",
            "46/46 - 0s - loss: 523.6929 - 93ms/epoch - 2ms/step\n",
            "Epoch 93/200\n",
            "46/46 - 0s - loss: 519.2479 - 93ms/epoch - 2ms/step\n",
            "Epoch 94/200\n",
            "46/46 - 0s - loss: 525.0283 - 96ms/epoch - 2ms/step\n",
            "Epoch 95/200\n",
            "46/46 - 0s - loss: 518.7251 - 99ms/epoch - 2ms/step\n",
            "Epoch 96/200\n",
            "46/46 - 0s - loss: 513.6580 - 90ms/epoch - 2ms/step\n",
            "Epoch 97/200\n",
            "46/46 - 0s - loss: 517.2687 - 94ms/epoch - 2ms/step\n",
            "Epoch 98/200\n",
            "46/46 - 0s - loss: 523.6867 - 90ms/epoch - 2ms/step\n",
            "Epoch 99/200\n",
            "46/46 - 0s - loss: 521.3824 - 91ms/epoch - 2ms/step\n",
            "Epoch 100/200\n",
            "46/46 - 0s - loss: 520.6677 - 94ms/epoch - 2ms/step\n",
            "Epoch 101/200\n",
            "46/46 - 0s - loss: 514.3044 - 88ms/epoch - 2ms/step\n",
            "Epoch 102/200\n",
            "46/46 - 0s - loss: 518.0201 - 91ms/epoch - 2ms/step\n",
            "Epoch 103/200\n",
            "46/46 - 0s - loss: 535.2364 - 91ms/epoch - 2ms/step\n",
            "Epoch 104/200\n",
            "46/46 - 0s - loss: 515.7543 - 102ms/epoch - 2ms/step\n",
            "Epoch 105/200\n",
            "46/46 - 0s - loss: 515.3925 - 89ms/epoch - 2ms/step\n",
            "Epoch 106/200\n",
            "46/46 - 0s - loss: 537.8715 - 90ms/epoch - 2ms/step\n",
            "Epoch 107/200\n",
            "46/46 - 0s - loss: 515.3762 - 97ms/epoch - 2ms/step\n",
            "Epoch 108/200\n",
            "46/46 - 0s - loss: 522.8091 - 102ms/epoch - 2ms/step\n",
            "Epoch 109/200\n",
            "46/46 - 0s - loss: 511.9988 - 96ms/epoch - 2ms/step\n",
            "Epoch 110/200\n",
            "46/46 - 0s - loss: 511.8471 - 92ms/epoch - 2ms/step\n",
            "Epoch 111/200\n",
            "46/46 - 0s - loss: 521.9807 - 93ms/epoch - 2ms/step\n",
            "Epoch 112/200\n",
            "46/46 - 0s - loss: 528.7768 - 99ms/epoch - 2ms/step\n",
            "Epoch 113/200\n",
            "46/46 - 0s - loss: 522.6995 - 107ms/epoch - 2ms/step\n",
            "Epoch 114/200\n",
            "46/46 - 0s - loss: 509.6732 - 115ms/epoch - 3ms/step\n",
            "Epoch 115/200\n",
            "46/46 - 0s - loss: 523.9551 - 102ms/epoch - 2ms/step\n",
            "Epoch 116/200\n",
            "46/46 - 0s - loss: 525.9297 - 97ms/epoch - 2ms/step\n",
            "Epoch 117/200\n",
            "46/46 - 0s - loss: 498.3019 - 96ms/epoch - 2ms/step\n",
            "Epoch 118/200\n",
            "46/46 - 0s - loss: 573.8411 - 92ms/epoch - 2ms/step\n",
            "Epoch 119/200\n",
            "46/46 - 0s - loss: 521.1108 - 92ms/epoch - 2ms/step\n",
            "Epoch 120/200\n",
            "46/46 - 0s - loss: 508.2141 - 93ms/epoch - 2ms/step\n",
            "Epoch 121/200\n",
            "46/46 - 0s - loss: 515.3841 - 101ms/epoch - 2ms/step\n",
            "Epoch 122/200\n",
            "46/46 - 0s - loss: 511.5397 - 92ms/epoch - 2ms/step\n",
            "Epoch 123/200\n",
            "46/46 - 0s - loss: 530.9354 - 97ms/epoch - 2ms/step\n",
            "Epoch 124/200\n",
            "46/46 - 0s - loss: 507.9482 - 101ms/epoch - 2ms/step\n",
            "Epoch 125/200\n",
            "46/46 - 0s - loss: 507.0622 - 95ms/epoch - 2ms/step\n",
            "Epoch 126/200\n",
            "46/46 - 0s - loss: 502.2882 - 91ms/epoch - 2ms/step\n",
            "Epoch 127/200\n",
            "46/46 - 0s - loss: 508.0619 - 93ms/epoch - 2ms/step\n",
            "Epoch 128/200\n",
            "46/46 - 0s - loss: 505.1429 - 96ms/epoch - 2ms/step\n",
            "Epoch 129/200\n",
            "46/46 - 0s - loss: 514.7155 - 98ms/epoch - 2ms/step\n",
            "Epoch 130/200\n",
            "46/46 - 0s - loss: 533.7625 - 92ms/epoch - 2ms/step\n",
            "Epoch 131/200\n",
            "46/46 - 0s - loss: 515.4318 - 89ms/epoch - 2ms/step\n",
            "Epoch 132/200\n",
            "46/46 - 0s - loss: 518.3476 - 96ms/epoch - 2ms/step\n",
            "Epoch 133/200\n",
            "46/46 - 0s - loss: 516.5029 - 91ms/epoch - 2ms/step\n",
            "Epoch 134/200\n",
            "46/46 - 0s - loss: 508.5195 - 107ms/epoch - 2ms/step\n",
            "Epoch 135/200\n",
            "46/46 - 0s - loss: 506.8240 - 91ms/epoch - 2ms/step\n",
            "Epoch 136/200\n",
            "46/46 - 0s - loss: 507.4348 - 93ms/epoch - 2ms/step\n",
            "Epoch 137/200\n",
            "46/46 - 0s - loss: 520.0573 - 92ms/epoch - 2ms/step\n",
            "Epoch 138/200\n",
            "46/46 - 0s - loss: 504.5515 - 90ms/epoch - 2ms/step\n",
            "Epoch 139/200\n",
            "46/46 - 0s - loss: 540.4358 - 91ms/epoch - 2ms/step\n",
            "Epoch 140/200\n",
            "46/46 - 0s - loss: 519.8140 - 97ms/epoch - 2ms/step\n",
            "Epoch 141/200\n",
            "46/46 - 0s - loss: 521.9927 - 90ms/epoch - 2ms/step\n",
            "Epoch 142/200\n",
            "46/46 - 0s - loss: 496.4699 - 95ms/epoch - 2ms/step\n",
            "Epoch 143/200\n",
            "46/46 - 0s - loss: 503.3888 - 93ms/epoch - 2ms/step\n",
            "Epoch 144/200\n",
            "46/46 - 0s - loss: 505.2882 - 93ms/epoch - 2ms/step\n",
            "Epoch 145/200\n",
            "46/46 - 0s - loss: 498.8366 - 103ms/epoch - 2ms/step\n",
            "Epoch 146/200\n",
            "46/46 - 0s - loss: 500.5847 - 95ms/epoch - 2ms/step\n",
            "Epoch 147/200\n",
            "46/46 - 0s - loss: 507.8682 - 91ms/epoch - 2ms/step\n",
            "Epoch 148/200\n",
            "46/46 - 0s - loss: 505.9651 - 92ms/epoch - 2ms/step\n",
            "Epoch 149/200\n",
            "46/46 - 0s - loss: 499.1423 - 94ms/epoch - 2ms/step\n",
            "Epoch 150/200\n",
            "46/46 - 0s - loss: 513.9975 - 92ms/epoch - 2ms/step\n",
            "Epoch 151/200\n",
            "46/46 - 0s - loss: 521.3655 - 97ms/epoch - 2ms/step\n",
            "Epoch 152/200\n",
            "46/46 - 0s - loss: 496.1677 - 97ms/epoch - 2ms/step\n",
            "Epoch 153/200\n",
            "46/46 - 0s - loss: 503.9972 - 90ms/epoch - 2ms/step\n",
            "Epoch 154/200\n",
            "46/46 - 0s - loss: 520.9302 - 90ms/epoch - 2ms/step\n",
            "Epoch 155/200\n",
            "46/46 - 0s - loss: 500.3427 - 106ms/epoch - 2ms/step\n",
            "Epoch 156/200\n",
            "46/46 - 0s - loss: 500.4103 - 102ms/epoch - 2ms/step\n",
            "Epoch 157/200\n",
            "46/46 - 0s - loss: 499.1944 - 93ms/epoch - 2ms/step\n",
            "Epoch 158/200\n",
            "46/46 - 0s - loss: 527.5872 - 96ms/epoch - 2ms/step\n",
            "Epoch 159/200\n",
            "46/46 - 0s - loss: 498.5145 - 95ms/epoch - 2ms/step\n",
            "Epoch 160/200\n",
            "46/46 - 0s - loss: 498.9993 - 90ms/epoch - 2ms/step\n",
            "Epoch 161/200\n",
            "46/46 - 0s - loss: 496.4622 - 90ms/epoch - 2ms/step\n",
            "Epoch 162/200\n",
            "46/46 - 0s - loss: 518.0144 - 93ms/epoch - 2ms/step\n",
            "Epoch 163/200\n",
            "46/46 - 0s - loss: 492.4502 - 91ms/epoch - 2ms/step\n",
            "Epoch 164/200\n",
            "46/46 - 0s - loss: 505.3112 - 98ms/epoch - 2ms/step\n",
            "Epoch 165/200\n",
            "46/46 - 0s - loss: 500.6086 - 103ms/epoch - 2ms/step\n",
            "Epoch 166/200\n",
            "46/46 - 0s - loss: 497.7597 - 95ms/epoch - 2ms/step\n",
            "Epoch 167/200\n",
            "46/46 - 0s - loss: 534.0649 - 91ms/epoch - 2ms/step\n",
            "Epoch 168/200\n",
            "46/46 - 0s - loss: 509.1065 - 92ms/epoch - 2ms/step\n",
            "Epoch 169/200\n",
            "46/46 - 0s - loss: 522.7477 - 95ms/epoch - 2ms/step\n",
            "Epoch 170/200\n",
            "46/46 - 0s - loss: 502.6575 - 93ms/epoch - 2ms/step\n",
            "Epoch 171/200\n",
            "46/46 - 0s - loss: 510.7406 - 95ms/epoch - 2ms/step\n",
            "Epoch 172/200\n",
            "46/46 - 0s - loss: 522.4411 - 94ms/epoch - 2ms/step\n",
            "Epoch 173/200\n",
            "46/46 - 0s - loss: 492.1499 - 90ms/epoch - 2ms/step\n",
            "Epoch 174/200\n",
            "46/46 - 0s - loss: 490.8721 - 94ms/epoch - 2ms/step\n",
            "Epoch 175/200\n",
            "46/46 - 0s - loss: 500.9686 - 104ms/epoch - 2ms/step\n",
            "Epoch 176/200\n",
            "46/46 - 0s - loss: 528.6055 - 100ms/epoch - 2ms/step\n",
            "Epoch 177/200\n",
            "46/46 - 0s - loss: 524.1375 - 92ms/epoch - 2ms/step\n",
            "Epoch 178/200\n",
            "46/46 - 0s - loss: 489.0659 - 103ms/epoch - 2ms/step\n",
            "Epoch 179/200\n",
            "46/46 - 0s - loss: 493.6833 - 99ms/epoch - 2ms/step\n",
            "Epoch 180/200\n",
            "46/46 - 0s - loss: 504.5718 - 90ms/epoch - 2ms/step\n",
            "Epoch 181/200\n",
            "46/46 - 0s - loss: 511.0183 - 92ms/epoch - 2ms/step\n",
            "Epoch 182/200\n",
            "46/46 - 0s - loss: 497.5465 - 94ms/epoch - 2ms/step\n",
            "Epoch 183/200\n",
            "46/46 - 0s - loss: 512.0868 - 90ms/epoch - 2ms/step\n",
            "Epoch 184/200\n",
            "46/46 - 0s - loss: 494.2510 - 91ms/epoch - 2ms/step\n",
            "Epoch 185/200\n",
            "46/46 - 0s - loss: 489.8349 - 101ms/epoch - 2ms/step\n",
            "Epoch 186/200\n",
            "46/46 - 0s - loss: 503.3430 - 90ms/epoch - 2ms/step\n",
            "Epoch 187/200\n",
            "46/46 - 0s - loss: 496.9248 - 89ms/epoch - 2ms/step\n",
            "Epoch 188/200\n",
            "46/46 - 0s - loss: 498.7047 - 96ms/epoch - 2ms/step\n",
            "Epoch 189/200\n",
            "46/46 - 0s - loss: 501.8258 - 110ms/epoch - 2ms/step\n",
            "Epoch 190/200\n",
            "46/46 - 0s - loss: 493.5473 - 91ms/epoch - 2ms/step\n",
            "Epoch 191/200\n",
            "46/46 - 0s - loss: 504.6700 - 90ms/epoch - 2ms/step\n",
            "Epoch 192/200\n",
            "46/46 - 0s - loss: 486.2536 - 92ms/epoch - 2ms/step\n",
            "Epoch 193/200\n",
            "46/46 - 0s - loss: 500.1224 - 94ms/epoch - 2ms/step\n",
            "Epoch 194/200\n",
            "46/46 - 0s - loss: 489.2229 - 90ms/epoch - 2ms/step\n",
            "Epoch 195/200\n",
            "46/46 - 0s - loss: 512.6379 - 93ms/epoch - 2ms/step\n",
            "Epoch 196/200\n",
            "46/46 - 0s - loss: 494.9247 - 109ms/epoch - 2ms/step\n",
            "Epoch 197/200\n",
            "46/46 - 0s - loss: 489.6569 - 90ms/epoch - 2ms/step\n",
            "Epoch 198/200\n",
            "46/46 - 0s - loss: 493.4582 - 96ms/epoch - 2ms/step\n",
            "Epoch 199/200\n",
            "46/46 - 0s - loss: 489.6298 - 105ms/epoch - 2ms/step\n",
            "Epoch 200/200\n",
            "46/46 - 0s - loss: 515.0394 - 93ms/epoch - 2ms/step\n",
            "Train Score: 490.66 MSE (22.15 RMSE)\n",
            "Test Score: 1902.14 MSE (43.61 RMSE)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# one-hot-encoding\n",
        "### 14:00"
      ],
      "metadata": {
        "id": "zpWJLw6WXtsU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 입력 텍스트 데이터 -> 숫자 임베딩 -> target 예측 -> \n",
        "char_arr = [c for c in 'SEPabcdefghijklmnopqrstuvwxyz단어나무게임벨트놀이자료']\n",
        "# ['S', 'E', 'P', ............]\n",
        "num_dic = {n: i for i, n in enumerate(char_arr)}\n",
        "print(num_dic)\n",
        "dic_len = len(num_dic)\n",
        "print(dic_len) # 41자 : 100000 -> 100000개 짜리 벡터 (희소행렬)\n",
        "seq_data = [['word', '단어'], ['wood', '나무'],\n",
        "            ['game', '놀이'], ['girl', '소녀'],\n",
        "            ['test', '연습'], ['love', '사랑']]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lCR2ynHIC2Bn",
        "outputId": "3791554f-f940-40df-a099-6a8b7dd2c03b"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'S': 0, 'E': 1, 'P': 2, 'a': 3, 'b': 4, 'c': 5, 'd': 6, 'e': 7, 'f': 8, 'g': 9, 'h': 10, 'i': 11, 'j': 12, 'k': 13, 'l': 14, 'm': 15, 'n': 16, 'o': 17, 'p': 18, 'q': 19, 'r': 20, 's': 21, 't': 22, 'u': 23, 'v': 24, 'w': 25, 'x': 26, 'y': 27, 'z': 28, '단': 29, '어': 30, '나': 31, '무': 32, '게': 33, '임': 34, '벨': 35, '트': 36, '놀': 37, '이': 38, '자': 39, '료': 40}\n",
            "41\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "char_arr = [c for c in \"SEPabcdefghijklmnopqrstuvwxyz단어나무놀이소녀키스사랑봉구우루\"]\n",
        "num_dic = {n: i for i, n in enumerate(char_arr)}\n",
        "dic_len = len(num_dic)\n",
        "\n",
        "seq_data = [['word', \"단어\"], [\"wood\", \"나무\"], [\"game\", \"놀이\"], [\"girl\", \"소녀\"], \n",
        "            [\"kiss\", \"키스\"], [\"love\", \"사랑\"], [\"bong\", \"봉구\"], [\"uruu\", \"우루\"]]"
      ],
      "metadata": {
        "id": "lx32pJZ7Ev8I"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Embedding 함수 14:07\n",
        "import numpy as np\n",
        "def make_batch(seq_data): # seq 2 seq\n",
        "  input_batch = [] # 입력 : h_state (전단계의 셀에서 출력된 결과)\n",
        "  output_batch = [] # 번역입력\n",
        "  target_batch = [] # 예측\n",
        "  \n",
        "  for seq in seq_data: # ['word', '단어']\n",
        "    input = [num_dic[n] for n in seq[0]] # 'word' :  w:25으로 매핑시켜놓은거고 , o:17, r:20, d:6 => [25, 17, 20, 6]\n",
        "    output = [num_dic[n] for n in ('S' + seq[1])] # 시작  # 단 : 29,  어 : 30 => 결과적으로 이렇게 만들어지죠 [0, 29, 30]\n",
        "    target = [num_dic[n] for n in (seq[1] + 'E')] # [29, 30, 1] # 종료지점\n",
        "    # one-hot-encoding\n",
        "    ## 쭉 대각선으로 표시하게 되면 x를 표시하게 된다고 하면\n",
        "    # 1, 0 0 0 0 0 0 0000000 : 41차 1차원벡터\n",
        "    # 0,1,00000000000000000000\n",
        "    # 0 0 1 00 00 0\n",
        "    # 0 0 0 1 0 0 0 0 0\n",
        "    input_batch.append(np.eye(dic_len)[input]) # 단위행렬을 만드는 함수 identity ## 14:15\n",
        "    # [ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 00000000] 이런 벡터가 하나 만들어지고\n",
        "    # [ 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]\n",
        "    ## 전체 몇차원 벡터?\n",
        "    # 4 x 41짜리 벡터가 행렬이 만들어지는거죠?\n",
        "    ## 똑같은 원리로 \n",
        "    output_batch.append(np.eye(dic_len)[output]) # 출력 행렬 3 x 41\n",
        "    target_batch.append(target) # 종속변수 행렬이 3 x 41개로 만들어지겠죠\n",
        "  return input_batch, output_batch, target_batch"
      ],
      "metadata": {
        "id": "gNzVXXTiHn-o"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_batch(seq_data):\n",
        "    input_batch = []\n",
        "    output_batch = []\n",
        "    target_batch = []\n",
        "    \n",
        "    for seq in seq_data:\n",
        "        input = [num_dic[n] for n in seq[0]]\n",
        "        output = [num_dic[n] for n in (\"S\" + seq[1])]\n",
        "        target = [num_dic[n] for n in (seq[1] + \"E\")]\n",
        "        \n",
        "        input_batch.append(np.eye(dic_len)[input])\n",
        "        output_batch.append(np.eye(dic_len)[output])\n",
        "        target_batch.append(target)\n",
        "        \n",
        "    return input_batch, output_batch, target_batch"
      ],
      "metadata": {
        "id": "AsR9OaRFDxkU"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "mId8XprIcEks"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_batch, output_batch, target_batch = make_batch(seq_data)"
      ],
      "metadata": {
        "id": "tFZHZEWBIMJ8"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(input_batch)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gfrEbAFRD8WT",
        "outputId": "3226131e-3482-4a2d-af22-e6238a7ef76d"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## 14:26"
      ],
      "metadata": {
        "id": "_YDMZx0wdSoU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 시간 데이터 (자기상관성) => 독립변수 + 종속변수\n",
        "from keras.preprocessing.sequence import TimeseriesGenerator\n",
        "import numpy as np\n",
        "data = np.array([[i] for i in range(50)]) # 0 ~ 49까지 [ [0], [1], [2], ... ] 이렇게 바꾸라는 것\n",
        "targets = np.array([[i] for i in range(50)]) # 0 ~ 49까지 [ [0], [1], [2], ... ] 이렇게 바꾸라는 것\n",
        "print(data[:10])\n",
        "# 4개씩 (분기별로 종속성을 가지고 있는 경우)\n",
        "data_gen = TimeseriesGenerator(data, targets,\n",
        "                               length=10, sampling_rate=2,\n",
        "                               batch_size=2)\n",
        "assert len(data_gen) == 20\n",
        "batch_0 = data_gen[0] # tuple 데이터이다.\n",
        "print(\"데이터 구조 \", batch_0)\n",
        "x, y = batch_0\n",
        "# 검증에러 ## 에러를 검증하기 위해 쓰는 것 assert np.array\n",
        "## 프로젝트 할 때는 주석 잡을 것\n",
        "## 프로그램 만들 때는 없어야한다\n",
        "assert np.array_equal(x,\n",
        "                      np.array([[[0], [2], [4], [6], [8]],\n",
        "                               [[1], [3], [5], [7], [9]]])) # 2 4 6 8 10, 3부터 시작하면 3 5 7 9 11\n",
        "                               ## 괄호 개수 잘 파악\n",
        "assert np.array_equal(y,\n",
        "                      np.array([[10], [11]]))\n",
        "print(\"마지막에 생성된 데이터\")\n",
        "data_gen[19] ## 19번째를 보게 되어지니까 array([[48],[49]])"
      ],
      "metadata": {
        "id": "3DOAf8cFITnc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "83a04451-bb1a-4216-b01a-c1953a95de8c"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0]\n",
            " [1]\n",
            " [2]\n",
            " [3]\n",
            " [4]\n",
            " [5]\n",
            " [6]\n",
            " [7]\n",
            " [8]\n",
            " [9]]\n",
            "데이터 구조  (array([[[0],\n",
            "        [2],\n",
            "        [4],\n",
            "        [6],\n",
            "        [8]],\n",
            "\n",
            "       [[1],\n",
            "        [3],\n",
            "        [5],\n",
            "        [7],\n",
            "        [9]]]), array([[10],\n",
            "       [11]]))\n",
            "마지막에 생성된 데이터\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[[38],\n",
              "         [40],\n",
              "         [42],\n",
              "         [44],\n",
              "         [46]],\n",
              " \n",
              "        [[39],\n",
              "         [41],\n",
              "         [43],\n",
              "         [45],\n",
              "         [47]]]), array([[48],\n",
              "        [49]]))"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 순위"
      ],
      "metadata": {
        "id": "KY83Wo4rfD3v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.preprocessing.text import one_hot\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, Flatten, Dense\n",
        "docs = ['Well done!', 'Good work', 'Great effort', 'nice work', 'Excellent!',\n",
        "        'Weak', 'Poor effort!', 'not good', 'poor work', 'Could have done better.']"
      ],
      "metadata": {
        "id": "J6SFeEeydGT2"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels = [1, 1, 1, 1, 1, 0, 0, 0, 0, 0] # 긍정, 부정 분류하는 것\n",
        "own_embedding_vocab_size = 10\n",
        "# 10개로 구성된 벡터\n",
        "# Well, done, good, work, great, effort, nice, excellent, weak, poor, not, could, have, better\n",
        "# Great, nice, well [3, 7]. [1, 5] 번호가 부여가 되었죠 이게 원핫인코딩입니다\n",
        "encoded_docs_oe = [one_hot(d, own_embedding_vocab_size) for d in docs]\n",
        "print(encoded_docs_oe)\n",
        "maxlen = 5\n",
        "# cnn의 padding처럼 단어도 패딩 => 사이즈를 일치시키기 위해서 ( 텍스트는 사이즈 일치 : one-hot-encoding, word2vec, fasttext, glove)\n",
        "padded_docs_oe = pad_sequences(encoded_docs_oe, maxlen=maxlen, padding='post')\n",
        "print(padded_docs_oe)\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=own_embedding_vocab_size, # 10개로 구성된 단어\n",
        "                    output_dim=32, # 단어 간의 유사성을 고려해서 임베딩 (유사성을 고려해주는 방식은 word2vec이죠?) => 벡터로 변환\n",
        "                    input_length=maxlen)) # 길이 사이즈를 지정\n",
        "model.add(Flatten())\n",
        "model.add(Dense(1, activation='sigmoid')) #FFNN : 0.5를 기준으로 1.0으로 예측\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
        "print(model.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eTRbq42qfmsC",
        "outputId": "3c6bbc8e-cc6f-4dfa-96db-86815b76073b"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[5, 4], [7, 7], [1, 9], [6, 7], [6], [7], [1, 9], [5, 7], [1, 7], [7, 7, 4, 4]]\n",
            "[[5 4 0 0 0]\n",
            " [7 7 0 0 0]\n",
            " [1 9 0 0 0]\n",
            " [6 7 0 0 0]\n",
            " [6 0 0 0 0]\n",
            " [7 0 0 0 0]\n",
            " [1 9 0 0 0]\n",
            " [5 7 0 0 0]\n",
            " [1 7 0 0 0]\n",
            " [7 7 4 4 0]]\n",
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 5, 32)             320       \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 160)               0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 1)                 161       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 481\n",
            "Trainable params: 481\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2iKL009Hp237",
        "outputId": "323be4ba-2707-4e69-bb89-93c4c76cfcc2"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "labels = np.array(labels)\n",
        "labels = labels.reshape((-1, 1))\n",
        "#model.fit(tf.Tensor(padded_docs_oe), labels, epochs=50, verbose=0)\n",
        "loss, accuracy = model.evaluate(padded_docs_oe, labels, verbose=0)\n",
        "print('Accuracy: %0.3f' % accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U7OIoRzCgCrB",
        "outputId": "19f704a8-1b46-4e89-e61e-b45ff085e85c"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "np.random.seed(1337)\n",
        "\n",
        "from tensorflow.keras.datasets import reuters\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Activation\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "# 로이터는 신문 기사 -> 그룹별로 그룹핑 (경제, 사회, 문화, ...)\n",
        "max_words = 1000\n",
        "batch_size = 100\n",
        "nb_epoch = 200\n",
        "(X_train, y_train), (X_test, y_test) = reuters.load_data(num_words=max_words, test_split=0.2) # 8:2로 분할"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DlaNxHVJmAo3",
        "outputId": "7d491017-2b43-4870-ae3d-83a083847c3b"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/reuters.npz\n",
            "2110848/2110848 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(X_train)\n",
        "X_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gjtxSriEqa7C",
        "outputId": "5c694a7a-d68e-4509-e409-130cd5237a46"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8982,)"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nb_classes = np.max(y_train)+1 # 그룹번호를 지정할 때 0부터 시작해서 순서적으로 (가장 큰 라벨 번호 +1)\n",
        "print(nb_classes) # 46개의 기사 그룹이 분류가 되있다는 소리죠 ## 15:26\n",
        "tokenizer = Tokenizer(num_words=max_words) # 1000개의 단어로 구성\n",
        "tokenizer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yeys06hKpIMs",
        "outputId": "1e26d587-dd21-4a7f-b346-784fb3e64a31"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "46\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.preprocessing.text.Tokenizer at 0x7ff887cea890>"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "U6s-twaBpgoj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = tokenizer.sequences_to_matrix(X_train, mode='binary') # one-hot-encoding\n",
        "X_test = tokenizer.sequences_to_matrix(X_test, mode='binary')\n",
        "# 신경망에서는 ㅡ종속변수는 반드시 one-hot-encoding 해주어야 함\n",
        "Y_train = to_categorical(y_train, nb_classes)\n",
        "Y_test = to_categorical(y_test, nb_classes)\n",
        "print(Y_train.shape) # (8982, 46)\n",
        "print(Y_train[:3])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ud-LFUgApTbb",
        "outputId": "2ad1ca84-dde8-49ab-ffac-fbbe3a28f5fb"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(8982, 46)\n",
            "[[0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 기사 그룹\n",
        "- 46개의 기사 그룹\n",
        "- 로이터(reuters)에는 one-hot-encoding되어진 숫자로 이뤄진 데이터가 입력"
      ],
      "metadata": {
        "id": "htRCeLWusmLM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train[0] # 가장 긴 기사 : 1000 one-hot-encoding의 의미\n",
        "# 임금, 이자율, 경제성장률"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qavx5rrwsIN3",
        "outputId": "f5369c69-3f4b-41fa-a5be-3c879ea72a2e"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1.,\n",
              "       1., 0., 1., 0., 0., 1., 0., 0., 1., 1., 0., 0., 1., 1., 0., 1., 0.,\n",
              "       0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 1., 1., 0.,\n",
              "       0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.,\n",
              "       0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       1., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
              "       0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
              "       1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 현재 FFNN만을 이용해서 문서 분류를 실행함\n",
        "model = Sequential()\n",
        "model.add(Dense(512, input_shape=(max_words,), activation=\"relu\")) #1000x512 가중치 사이즈\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(nb_classes, activation=\"softmax\")) # 512 x 46\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(X_train, Y_train, epochs=nb_epoch, batch_size=batch_size, verbose =0, validation_split=0.1) ## verbose는 조용히 돌아가라(머신러닝)는 뜻\n",
        "score = model.evaluate(X_test, Y_test, batch_size=batch_size, verbose=1)\n",
        "print('\\n\\nModel accuracy %.2f%%' % (score[1]*100))\n",
        "print(\"Model loss : %.2f%%\" % (score[0]*100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gICY_BetnPCU",
        "outputId": "eacd3fc4-bf05-4647-d012-3083d24e353a"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 [==============================] - 0s 3ms/step - loss: 1.9314 - accuracy: 0.7867\n",
            "\n",
            "\n",
            "Model accuracy 78.67%\n",
            "Model loss : 193.14%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.text import text_to_word_sequence\n",
        "text = \"해보지 않으면 해낼 수 없다\"\n",
        "result = text_to_word_sequence(text)\n",
        "print(\"\\n원문:\\n\", text)\n",
        "print(\"\\n토큰화:\\n\", result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mJq1V0emojNB",
        "outputId": "17b2674f-cc9d-4d83-abe0-587a9f63f299"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "원문:\n",
            " 해보지 않으면 해낼 수 없다\n",
            "\n",
            "토큰화:\n",
            " ['해보지', '않으면', '해낼', '수', '없다']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "docs = [\"너무 재밌네요\",\"최고예요\",\"참 잘 만든 영화예요\",\"추천하고 싶은 영화입니다\",\"한번 더 보고싶네요\",\"글쎄요\",\"별로예요\",\"생각보다 지루하네요\",\"연기가 어색해요\",\"재미없어요\"]\n",
        "classes = np.array([1,1,1,1,1,0,0,0,0,0]) ## array([1,1,1,1,1,0,0,0,0,0])\n",
        "\n",
        "token = Tokenizer()\n",
        "token.fit_on_texts(docs) # 미리학습\n",
        "print(token.word_index)\n",
        "x = token.texts_to_sequences(docs) # \n",
        "print(\"\\n리뷰 텍스트, 토큰화 결과:\\n\", x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rxtma0DOtt9I",
        "outputId": "315859ca-f998-4aac-e18b-6028933db6d0"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'너무': 1, '재밌네요': 2, '최고예요': 3, '참': 4, '잘': 5, '만든': 6, '영화예요': 7, '추천하고': 8, '싶은': 9, '영화입니다': 10, '한번': 11, '더': 12, '보고싶네요': 13, '글쎄요': 14, '별로예요': 15, '생각보다': 16, '지루하네요': 17, '연기가': 18, '어색해요': 19, '재미없어요': 20}\n",
            "\n",
            "리뷰 텍스트, 토큰화 결과:\n",
            " [[1, 2], [3], [4, 5, 6, 7], [8, 9, 10], [11, 12, 13], [14], [15], [16, 17], [18, 19], [20]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "padded_x = pad_sequences(x, 4) # 동일 사이즈로 변환\n",
        "print(\"\\n 패딩 결과:\\n\", padded_x)\n",
        "print(\"\\n딥러닝 모델 시작:\")\n",
        "word_size = len(token.word_index) +1 # 전체 워드 사이즈\n",
        "model = Sequential()\n",
        "model.add(Embedding(word_size, 8, input_length=4)) # vectorizing함\n",
        "# 임베딩 -> vector로 변환 -> 1차원으로 FFNN으로 입력\n",
        "model.add(Flatten()) # 2차원 vector가 1차원 변환\n",
        "model.add(Dense(1, activation='sigmoid')) # 예측\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model.fit(padded_x, classes, epochs=20)\n",
        "print(\"\\n Accuracy: %.4f\" % (model.evaluate(padded_x, classes)[1]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gvWc5hPuuPvX",
        "outputId": "961f8289-7904-434c-bda5-0c5f9d77d517"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " 패딩 결과:\n",
            " [[ 0  0  1  2]\n",
            " [ 0  0  0  3]\n",
            " [ 4  5  6  7]\n",
            " [ 0  8  9 10]\n",
            " [ 0 11 12 13]\n",
            " [ 0  0  0 14]\n",
            " [ 0  0  0 15]\n",
            " [ 0  0 16 17]\n",
            " [ 0  0 18 19]\n",
            " [ 0  0  0 20]]\n",
            "\n",
            "딥러닝 모델 시작:\n",
            "Epoch 1/20\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 0.6922 - accuracy: 0.5000\n",
            "Epoch 2/20\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.6904 - accuracy: 0.5000\n",
            "Epoch 3/20\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6886 - accuracy: 0.5000\n",
            "Epoch 4/20\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6869 - accuracy: 0.5000\n",
            "Epoch 5/20\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6851 - accuracy: 0.6000\n",
            "Epoch 6/20\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6833 - accuracy: 0.6000\n",
            "Epoch 7/20\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6816 - accuracy: 0.6000\n",
            "Epoch 8/20\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6798 - accuracy: 0.6000\n",
            "Epoch 9/20\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6780 - accuracy: 0.8000\n",
            "Epoch 10/20\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6763 - accuracy: 0.8000\n",
            "Epoch 11/20\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6745 - accuracy: 0.8000\n",
            "Epoch 12/20\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6727 - accuracy: 0.9000\n",
            "Epoch 13/20\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6709 - accuracy: 0.9000\n",
            "Epoch 14/20\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6692 - accuracy: 0.9000\n",
            "Epoch 15/20\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6674 - accuracy: 0.9000\n",
            "Epoch 16/20\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6655 - accuracy: 0.9000\n",
            "Epoch 17/20\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6637 - accuracy: 0.9000\n",
            "Epoch 18/20\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6619 - accuracy: 0.9000\n",
            "Epoch 19/20\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6601 - accuracy: 0.9000\n",
            "Epoch 20/20\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6582 - accuracy: 0.9000\n",
            "1/1 [==============================] - 0s 103ms/step - loss: 0.6564 - accuracy: 0.9000\n",
            "\n",
            " Accuracy: 0.9000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# RNN 이해 -> LSTM(long short term memory)을 사용\n",
        "# - 기울기 vanishing(소실 문제가 해결)"
      ],
      "metadata": {
        "id": "N5Kt0kocu1Gl"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense,LSTM,Embedding\n",
        "model = Sequential()\n",
        "model.add(Embedding(1000, 100))\n",
        "model.add(LSTM(100, activation='tanh'))\n",
        "model.add(Dense(46, activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer = 'adam',\n",
        "              metrics=['accuracy'])\n",
        "history = model.fit(X_train, Y_train, batch_size=100, epochs=20, validation_data=(X_test, Y_test)) ## epochs=20"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R1ZNFbAZzma4",
        "outputId": "133d7526-ed88-4ac5-e489-f86685192887"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "90/90 [==============================] - 8s 62ms/step - loss: 2.5766 - accuracy: 0.3486 - val_loss: 2.4206 - val_accuracy: 0.3620\n",
            "Epoch 2/20\n",
            "90/90 [==============================] - 5s 55ms/step - loss: 2.4129 - accuracy: 0.3517 - val_loss: 2.4210 - val_accuracy: 0.3620\n",
            "Epoch 3/20\n",
            "90/90 [==============================] - 5s 55ms/step - loss: 2.4102 - accuracy: 0.3517 - val_loss: 2.4150 - val_accuracy: 0.3620\n",
            "Epoch 4/20\n",
            "90/90 [==============================] - 5s 57ms/step - loss: 2.4097 - accuracy: 0.3517 - val_loss: 2.4207 - val_accuracy: 0.3620\n",
            "Epoch 5/20\n",
            "90/90 [==============================] - 5s 59ms/step - loss: 2.4075 - accuracy: 0.3517 - val_loss: 2.4135 - val_accuracy: 0.3620\n",
            "Epoch 6/20\n",
            "90/90 [==============================] - 5s 57ms/step - loss: 2.3987 - accuracy: 0.3517 - val_loss: 2.4159 - val_accuracy: 0.3620\n",
            "Epoch 7/20\n",
            "90/90 [==============================] - 5s 59ms/step - loss: 2.3885 - accuracy: 0.3537 - val_loss: 2.3885 - val_accuracy: 0.3642\n",
            "Epoch 8/20\n",
            "90/90 [==============================] - 5s 57ms/step - loss: 2.3566 - accuracy: 0.3592 - val_loss: 2.3544 - val_accuracy: 0.3713\n",
            "Epoch 9/20\n",
            "90/90 [==============================] - 5s 57ms/step - loss: 2.2824 - accuracy: 0.3664 - val_loss: 2.2670 - val_accuracy: 0.3807\n",
            "Epoch 10/20\n",
            "90/90 [==============================] - 5s 58ms/step - loss: 2.2526 - accuracy: 0.3744 - val_loss: 2.2515 - val_accuracy: 0.3865\n",
            "Epoch 11/20\n",
            "90/90 [==============================] - 5s 57ms/step - loss: 2.2384 - accuracy: 0.3820 - val_loss: 2.2363 - val_accuracy: 0.3869\n",
            "Epoch 12/20\n",
            "90/90 [==============================] - 5s 58ms/step - loss: 2.2309 - accuracy: 0.3855 - val_loss: 2.2348 - val_accuracy: 0.3927\n",
            "Epoch 13/20\n",
            "90/90 [==============================] - 5s 59ms/step - loss: 2.2310 - accuracy: 0.3841 - val_loss: 2.2263 - val_accuracy: 0.3972\n",
            "Epoch 14/20\n",
            "90/90 [==============================] - 5s 58ms/step - loss: 2.2265 - accuracy: 0.3838 - val_loss: 2.1980 - val_accuracy: 0.4118\n",
            "Epoch 15/20\n",
            "90/90 [==============================] - 5s 59ms/step - loss: 2.1648 - accuracy: 0.4215 - val_loss: 2.1309 - val_accuracy: 0.4573\n",
            "Epoch 16/20\n",
            "90/90 [==============================] - 5s 59ms/step - loss: 2.1128 - accuracy: 0.4545 - val_loss: 2.1162 - val_accuracy: 0.4581\n",
            "Epoch 17/20\n",
            "90/90 [==============================] - 5s 59ms/step - loss: 2.1023 - accuracy: 0.4575 - val_loss: 2.1112 - val_accuracy: 0.4599\n",
            "Epoch 18/20\n",
            "90/90 [==============================] - 5s 60ms/step - loss: 2.0961 - accuracy: 0.4540 - val_loss: 2.1075 - val_accuracy: 0.4626\n",
            "Epoch 19/20\n",
            "90/90 [==============================] - 5s 60ms/step - loss: 2.0879 - accuracy: 0.4581 - val_loss: 2.1212 - val_accuracy: 0.4492\n",
            "Epoch 20/20\n",
            "90/90 [==============================] - 5s 60ms/step - loss: 2.0966 - accuracy: 0.4545 - val_loss: 2.1045 - val_accuracy: 0.4608\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n Test Accuracy: %.4f\" % (model.evaluate(X_test, Y_test)[1]))\n",
        "y_vloss = history.history['val_loss']\n",
        "y_loss = history.history['loss']\n",
        "x_len = numpy.arange(len(y_loss))\n",
        "plt.plot(x_len, y_vloss, marker='.', c=\"red\", label=\"Testset_loss\")\n",
        "plt.plot(x_len, y_loss, marker='.', c=\"blue\", label=\"Trainset_loss\")\n",
        "plt.legend(loc='upper right')\n",
        "plt.grid()\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('loss')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 338
        },
        "id": "1FPNP0VO0HO8",
        "outputId": "66bfde0c-56c7-464b-a3d3-f5b2c04f43ad"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "71/71 [==============================] - 1s 15ms/step - loss: 2.1045 - accuracy: 0.4608\n",
            "\n",
            " Test Accuracy: 0.4608\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LSTM 16:00\n",
        "- IMDB (internet moview Database) : 25000개의 리뷰 학습\n",
        "- 영화관련정보, 출연진 정보, 개봉정보, 영화 후기, 평점\n",
        "- 긍정 부정 분류\n",
        "- convolution -> Conv1D(텍스트), Conv2D(이미지), Conv3D(영화)"
      ],
      "metadata": {
        "id": "T2_BsYY-3o3D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.datasets import imdb\n",
        "from tensorflow.keras.layers import Embedding\n",
        "from tensorflow.keras.layers import LSTM\n",
        "from tensorflow.keras.layers import Conv1D, MaxPooling1D\n",
        "from tensorflow.keras.preprocessing import sequence\n",
        "import numpy\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "A2Ou036k29BZ"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seed = 0\n",
        "numpy.random.seed(seed)\n",
        "tf.random.set_seed(3)\n",
        "# 1개의 영화평이 5000이상 안 됨\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=5000)\n",
        "x_train = sequence.pad_sequences(x_train, maxlen=100) # 100개의 단어로\n",
        "x_test = sequence.pad_sequences(x_test, maxlen=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O_sV7VU34Yx2",
        "outputId": "cdf511bf-41dd-471c-aa1a-38fcb1d08767"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "17464789/17464789 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 문장 -> vectorizing -> document vector -> \n",
        "x_train[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dvsQ5DW_9ksv",
        "outputId": "74183dce-dfd9-4da0-e87b-9c9df16e9f9b"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1415,   33,    6,   22,   12,  215,   28,   77,   52,    5,   14,\n",
              "        407,   16,   82,    2,    8,    4,  107,  117,    2,   15,  256,\n",
              "          4,    2,    7, 3766,    5,  723,   36,   71,   43,  530,  476,\n",
              "         26,  400,  317,   46,    7,    4,    2, 1029,   13,  104,   88,\n",
              "          4,  381,   15,  297,   98,   32, 2071,   56,   26,  141,    6,\n",
              "        194,    2,   18,    4,  226,   22,   21,  134,  476,   26,  480,\n",
              "          5,  144,   30,    2,   18,   51,   36,   28,  224,   92,   25,\n",
              "        104,    4,  226,   65,   16,   38, 1334,   88,   12,   16,  283,\n",
              "          5,   16, 4472,  113,  103,   32,   15,   16,    2,   19,  178,\n",
              "         32], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(5000, 100)) # 100개의 벡터로 표현\n",
        "model.add(Dropout(0, 5)) # 과적합 줄이기 위해 계산 생략\n",
        "# 채널수 -> 특징을 몇 번 잡는가?\n",
        "# 주변의 5개를 보고 적분으로 특징을 잡아낸다.\n",
        "# 나는 학교에 옆집 친구하고 아침 7시에 출발해서 8시에 도착한다.\n",
        "# 1, 2\n",
        "# 9-5 + 1 => 5개의 특징을 잡아낸다.\n",
        "# same => padding, valid는 패딩을 하지 않고 계산 사이즈대로 출력 => 5개가 출력된다 \n",
        "## 16:38\n",
        "model.add(Conv1D(64, 5, padding='valid', activation='relu', strides=1))\n",
        "model.add(MaxPooling1D(pool_size=4))\n",
        "model.add(LSTM(55)) # 55개의 사이즈로 출력\n",
        "model.add(Dense(1)) # 55 X 1개로 예측을 함\n",
        "model.add(Activation('sigmoid')) ## sigmoid니까 # 0.5를 기준으로 TRUE/FALSE ## 16:40\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HScvA1994sii",
        "outputId": "52ff46fc-5c9e-44a4-b94f-08835fcb7637"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_3 (Embedding)     (None, None, 100)         500000    \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, None, 100)         0         \n",
            "                                                                 \n",
            " conv1d (Conv1D)             (None, None, 64)          32064     \n",
            "                                                                 \n",
            " max_pooling1d (MaxPooling1D  (None, None, 64)         0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 55)                26400     \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 1)                 56        \n",
            "                                                                 \n",
            " activation_3 (Activation)   (None, 1)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 558,520\n",
            "Trainable params: 558,520\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "#history = model.fit(x_train, y_train, batch_size=100, epochs=5, \n",
        "#                    validation_data=(x_test, y_test))\n",
        "print(\"\\n Test Accuracy: %.4f\" % (model.evaluate(x_test, y_test)[1]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XRn-IGup5KHC",
        "outputId": "905e26a7-49b4-44c0-80d5-03377d73e787"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "782/782 [==============================] - 3s 3ms/step - loss: 0.6933 - accuracy: 0.4910\n",
            "\n",
            " Test Accuracy: 0.4910\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##17:00\n",
        "print(type(x_train))\n",
        "print(x_train.shape)\n",
        "print(x_train[20001])\n",
        "print(type(x_train[20000]))\n",
        "print(y_train[1])\n",
        "# 단어에 대한 인덱싱\n",
        "dictionary=imdb.get_word_index(path='imdb_word_index.json') # 키이 : 데이터\n",
        "print(type(dictionary)) # dictionary형태\n",
        "print(len(dictionary)) # 88584개의 단어로 구성\n",
        "imdb_key=dictionary.keys()\n",
        "print(type(imdb_key))\n",
        "\n",
        "print(list(imdb_key)[10]) # tsukino 단어 출력\n",
        "list(imdb_key)[1]\n",
        "keytotal=list(imdb_key)\n",
        "sentance = []\n",
        "for x, num in enumerate(x_train[10]):\n",
        "  res = keytotal[x]\n",
        "  sentance.append(res)\n",
        "print(sentance)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xpD3i0Ca5voR",
        "outputId": "211f98d5-8798-41e8-9e58-cb81b442f275"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'numpy.ndarray'>\n",
            "(25000, 100)\n",
            "[  87   51  575   36   26  502    8   79  101  156    5 1507   36  181\n",
            "    4  118    7   68   58   21  820  910 1030    8    2  183   56   11\n",
            " 2716    7   68    2 4697   10   10  910   70 4146    4  118  927    4\n",
            "  118 1180    5  907   21  131   36    2  183   56   14   20    9  595\n",
            "    4  619  155    9   15   13 1781  910   11   68    2  127   24   60\n",
            "  124   54    6   20    9   52   42   78   10   10   12    9   64  688\n",
            "    8    4  676    7    4  156   15   13   70   60  202   12    6  342\n",
            "    7  158]\n",
            "<class 'numpy.ndarray'>\n",
            "0\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb_word_index.json\n",
            "1641221/1641221 [==============================] - 0s 0us/step\n",
            "<class 'dict'>\n",
            "88584\n",
            "<class 'dict_keys'>\n",
            "hold's\n",
            "['fawn', 'tsukino', 'nunnery', 'sonja', 'vani', 'woods', 'spiders', 'hanging', 'woody', 'trawling', \"hold's\", 'comically', 'localized', 'disobeying', \"'royale\", \"harpo's\", 'canet', 'aileen', 'acurately', \"diplomat's\", 'rickman', 'arranged', 'rumbustious', 'familiarness', \"spider'\", 'hahahah', \"wood'\", 'transvestism', \"hangin'\", 'bringing', 'seamier', 'wooded', 'bravora', 'grueling', 'wooden', 'wednesday', \"'prix\", 'altagracia', 'circuitry', 'crotch', 'busybody', \"tart'n'tangy\", 'burgade', 'thrace', \"tom's\", 'snuggles', 'francesco', 'complainers', 'templarios', '272', '273', 'zaniacs', '275', 'consenting', 'snuggled', 'inanimate', 'uality', 'bronte', 'errors', 'dialogs', \"yomada's\", \"madman's\", 'dialoge', 'usenet', 'videodrome', \"kid'\", 'pawed', \"'girlfriend'\", \"'pleasure\", \"'reloaded'\", \"kazakos'\", 'rocque', 'mailings', 'brainwashed', 'mcanally', \"tom''\", 'kurupt', 'affiliated', 'babaganoosh', \"noe's\", 'quart', 'kids', 'uplifting', 'controversy', 'kida', 'kidd', \"error'\", 'neurologist', 'spotty', 'cobblers', 'projection', 'fastforwarding', 'sters', \"eggar's\", 'etherything', 'gateshead', 'airball', 'unsinkable', 'stern', \"cervi's\"]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ksRCn2fh9AOb"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1LqENlhkoJmOipdB6seHGGFumUbbCdBvQ",
      "authorship_tag": "ABX9TyP5HUz+8E+0ZtuGjJFx6BQx",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}